{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import tree\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('balance-scale.data', header=None, names=['C','LW','LD','RW','RD'])\n",
        "df\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of records where the format is ['description', mean, std]\n",
        "recording_list = []\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "X = df.loc[:, ['LW','LD','RW','RD']]\n",
        "y = df.loc[:, ['C']]\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "scores = cross_val_score(clf, X, y, cv=3)\n",
        "print('With 3 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With 3 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print('With 5 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With 5 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "scores = cross_val_score(clf, X, y, cv=10)\n",
        "print('With 10 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With 10 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like that the mean of cross validation results is affected by the number of specified folds during cross validation. It means that the decision tree model gets more accurate as you feed it a lot more data.\n",
        "\n",
        "Let's look at the importance of the features.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X, y)\n",
        "clf.feature_importances_\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like that importances of the attributes are balanced out well with a difference between 1 to 3 percent. Thus it means that pretty much they are equal to each other.\n",
        "\n",
        "Even though the balanced class (i.e. 'B') is only 8% of the dataset, models still looks like to struggle to perform good on average even though the it would have trained on a large number of 'L' or 'R' classes.\n",
        "\n",
        "I need to look at other machine learning algorithms to see whether they perform better.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "enc_y = LabelEncoder()\n",
        "enc_y.fit(np.ravel(y.to_numpy()))\n",
        "encoded_y = enc_y.transform(np.ravel(y.to_numpy()))\n",
        "clf = LogisticRegression(random_state=0)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With LogisticRegression', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With LogisticRegression', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With SGDClassifier', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With SGDClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(gamma='auto')\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With SVC', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With SVC', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC(max_iter=5000)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With LinearSVC', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With LinearSVC', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=200)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With RandomForestClassifier', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With RandomForestClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "clf = CategoricalNB()\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With CategoricalNB', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With CategoricalNB', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestCentroid\n",
        "clf = NearestCentroid()\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With NearestCentroid', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With NearestCentroid', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier()\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With KNeighborsClassifier', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With KNeighborsClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "clf = RadiusNeighborsClassifier(radius=2.0)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With RadiusNeighborsClassifier', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With RadiusNeighborsClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(max_iter=1200)\n",
        "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
        "print('With MLPClassifier', 'Mean:', scores.mean(), scores.std())\n",
        "recording_list.append(['With MLPClassifier', scores.mean(), scores.std()])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_list = sorted(recording_list, key=lambda item: item[1], reverse=True)\n",
        "for classifier, mean, std in sorted_list:\n",
        "    print(classifier, 'Mean:', mean, 'std:', std)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After experimenting with 11 algorithms, it looks like a neural network type classifier wins the testing round.\n",
        "\n",
        "Now I need to perform two things:\n",
        "    - I will need to delve further into algorithms to understand how they work as to have an idea why they perform either poorly or brilliantly. Algorithms I decided to learn about are:\n",
        "        1. MLPClassififer -- to understand neural networks in general\n",
        "        2. SGDClassifier -- to understand the stochastic classifier since it's second best\n",
        "        3. Decision Tree -- to understand decision trees since it's the worst model to train from the get go.\n",
        "    - During testing, I have been wondering about the current dataset and I think I have managed to notice few descrepencies I didn't see before. I will elaborate on this later.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```     ______                  __  _                ___\n",
        "    /  _/ /____  _________ _/ /_(_)___  ____     |__ \\\n",
        "    / // __/ _ \\/ ___/ __ `/ __/ / __ \\/ __ \\    __/ /\n",
        "  _/ // /_/  __/ /  / /_/ / /_/ / /_/ / / / /   / __/\n",
        " /___/\\__/\\___/_/   \\__,_/\\__/_/\\____/_/ /_/   /____/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose of this iteration is to see whether decision trees algorithms will be improved from its worse accuracy performance.\n",
        "\n",
        "The plan is to test different set of configurations and then do the same thing for feature engineered features.\n",
        "\n",
        "After reading about complex decisions trees that can fail to generalise a problem [Link](https://scikit-learn.org/stable/modules/tree.html#tree),\n",
        "the following has been advised to attempt to reduce the chances of such issue:\n",
        "- Set a required minimum samples at leaf nodes.\n",
        "- Set a depth level number to say how far the tree can go.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing parameters with original dataset\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "parameters = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
        "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
        "}\n",
        "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
        "X = df.loc[:, ['LW','LD','RW','RD']]\n",
        "y = df.loc[:, ['C']]\n",
        "clf.fit(X, y)\n",
        "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating columns for the calculated weights.\n",
        "left_array = df.loc[:, ['LW', 'LD']].to_numpy()\n",
        "calculations = [item[0] * item[1] for item in left_array]\n",
        "df['L_calc'] = calculations\n",
        "right_array = df.loc[:, ['RW', 'RD']].to_numpy()\n",
        "calculations = [item[0] * item[1] for item in right_array]\n",
        "df['R_calc'] = calculations\n",
        "df.head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing parameters with a new feature of calculations of weight and height for each side.\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "parameters = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
        "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
        "}\n",
        "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
        "X = df.loc[:, ['LW','LD','RW','RD', 'L_calc', 'R_calc']]\n",
        "y = df.loc[:, ['C']]\n",
        "clf.fit(X, y)\n",
        "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the configurations by using just the calculations of the weights and distance.\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "parameters = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
        "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
        "}\n",
        "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
        "X = df.loc[:, [ 'L_calc', 'R_calc']]\n",
        "y = df.loc[:, ['C']]\n",
        "clf.fit(X, y)\n",
        "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
        "\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like by introducing the calculations of weights and heights for each side helped the decision tree tremendously. Especially when only providing the calculatins on their own.\n",
        "\n",
        "I suppose that such calculations is kinda like a cheat, because I think it makes it easier for the model to 'sense' the algorithmic logic.\n",
        "\n",
        "I am very interested to see what will happen if I introduce boolean flag features (like making a hot-spot (I think) type features that are used for neural networks).\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating feature columns to represent hot-spotted boolean values for the classes.\n",
        "samples_array = df.loc[:, ['LW', 'LD', 'RW', 'RD']].to_numpy()\n",
        "df['left_flag'] = [(item[0] * item[1]) > (item[2] * item[3]) for item in samples_array]\n",
        "df['right_flag'] = [(item[0] * item[1]) < (item[2] * item[3]) for item in samples_array]\n",
        "df['balanced_flag'] = [(item[0] * item[1]) == (item[2] * item[3]) for item in samples_array]\n",
        "df.head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the configurations by using just the calculations of the weights and distance.\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "parameters = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
        "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
        "}\n",
        "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
        "X = df.loc[:, ['LW', 'LD', 'RW', 'RD', 'left_flag', 'balanced_flag', 'right_flag']]\n",
        "y = df.loc[:, ['C']]\n",
        "clf.fit(X, y)\n",
        "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the configurations by using just the calculations of the weights and distance.\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "parameters = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
        "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
        "}\n",
        "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
        "X = df.loc[:, ['left_flag', 'balanced_flag', 'right_flag']]\n",
        "y = df.loc[:, ['C']]\n",
        "clf.fit(X, y)\n",
        "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusions after trying feature engineering:\n",
        "- Calculated weights on each side:\n",
        "  - with the rest of features, it's on average 90%\n",
        "  - on their own, it's staggering 97%\n",
        "- Boolean flags\n",
        "  - With or without the rest of the feautres, it's pretty much 100%.\n",
        "    - In other words, I have already done the job for the algorithm :smiley:.\n",
        "\n",
        "Thus, it seems that the calculated weights of the features helps to make better guesses about the incoming values whereas the boolean flags are cheats.\n",
        "\n",
        "The next experiment will see whether I can make a model from balanced dataset where there are equal number of samples for each class.\n",
        "\n",
        "Before I do that though, I need to look into overfitting problems of the algorithm. During experiments, I noticed that the decision tree's accuracy would decrease\n",
        "if I fed it less training data when I performed different cross-validations (i.e. k-folds).\n",
        "What I would like to see is whether samples that sit on each end of the range (e.g. on value 1 and 5 rather than inbetween them) that can affect the accuracy and only use original features and the calculated weights.\n",
        "I will make the rations of class samples balanced as to be consistent with the mentioned experiment.\n",
        "\n",
        "ToDo Overfitting Experiments:\n",
        "- [x] Only upper values of the range (i.e. 5 in weights and distance no matter what in other values as long as conditions are met)\n",
        "    - ~[ ] With original features~\n",
        "    - [x] With original features and the calculated weights\n",
        "- [x] Only lower values of the range (i.e. 1 in weights and distance no matter what in other values as long as conditions are met)\n",
        "    - ~[ ] With original features~\n",
        "    - [x] With original features and the calculated weights\n",
        "- [x] Upper and lower values of the range (i.e. both of the prior conditions)\n",
        "    - ~[ ] With original features~\n",
        "    - [x] With original features and the calculated weights\n",
        "\n",
        "Update: just did some look up at the tree algorithm structures in 'looking_at_decision_trees_structre.py' file and its generated pdf documents.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_values_df = df[(df.LD == 5) | (df.LW == 5) | (df.RD == 5) | (df.RW == 5)]\n",
        "lower_values_df = df[(df.LD == 1) | (df.LW == 1) | (df.RD == 1) | (df.RW == 1)]\n",
        "upper_values_df.groupby('C').count()\n",
        "lower_values_df.groupby('C').count()\n",
        "\n",
        "# From the looks of it, I will choose 15 samples of each class for lower and upper values\n",
        "SEED = 1111\n",
        "\n",
        "# Making random samples for lower values by each class\n",
        "bal_df = lower_values_df[lower_values_df.C == 'B']\n",
        "left_df = lower_values_df[lower_values_df.C == 'L']\n",
        "right_df = lower_values_df[lower_values_df.C == 'R']\n",
        "\n",
        "bal_samples = bal_df.sample(n=15, random_state=SEED)\n",
        "left_samples = left_df.sample(n=15, random_state=SEED)\n",
        "right_samples = right_df.sample(n=15, random_state=SEED)\n",
        "\n",
        "lower_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
        "lower_samples_df.index\n",
        "\n",
        "# Making random samples for upper values by each class\n",
        "bal_df = upper_values_df[upper_values_df.C == 'B']\n",
        "left_df = upper_values_df[upper_values_df.C == 'L']\n",
        "right_df = upper_values_df[upper_values_df.C == 'R']\n",
        "bal_df.describe()\n",
        "left_df.describe()\n",
        "\n",
        "bal_samples = bal_df.sample(n=15, random_state=SEED)\n",
        "left_samples = left_df.sample(n=15, random_state=SEED)\n",
        "right_samples = right_df.sample(n=15, random_state=SEED)\n",
        "\n",
        "upper_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
        "upper_samples_df.index\n",
        "\n",
        "both_samples_df = pd.concat([lower_samples_df, upper_samples_df])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For dataset description purpose\n",
        "lower_samples_df.describe()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_samples_df.describe()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def separate_dataframe_from_training_one(original_df, training_df):\n",
        "    '''Return a newly-generated dataframe where one's rows don't exist in a training one'''\n",
        "    original_set = set(original_df.index)\n",
        "    training_set = set(training_df.index)\n",
        "    non_training_set = original_set - training_set\n",
        "    return original_df.iloc[list(non_training_set)]\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "separated_df = separate_dataframe_from_training_one(df, lower_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "X = lower_samples_df.loc[:, list_of_features]\n",
        "y = lower_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing tree into the dot format for observation\n",
        "# tree.export_graphviz(decision_tree_clf, out_file='lower_1_tree.dot')\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "separated_df = separate_dataframe_from_training_one(df, upper_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
        "X = upper_samples_df.loc[:, list_of_features]\n",
        "y = upper_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "separated_df = separate_dataframe_from_training_one(df, both_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
        "X = both_samples_df.loc[:, list_of_features]\n",
        "y = both_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like that the models still perform good even though I was expecting some overfitting problems. Even if there are only few samples to train from for particular boundaries\n",
        "(e.g. on average 70% accuracy for lower values and average 80)\n",
        "\n",
        "I believe it is because the samples have a wide range of values for weights and distances that still managed to make well-performed models\n",
        "(e.g. lower-values-only samples without the calculated weights would produce on average 59%).\n",
        "\n",
        "Thus, I shall make samples that only contain measurements that meet certain range criterial (i.e. maximum and minimum values)\n",
        "\n",
        "I believe this is because there's a wide range of the calculated weights for the classes and thus it helped the model\n",
        "to determine classes accurately. Like you can see below.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out the calculated weights\n",
        "upper_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
        "lower_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
        "both_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
        "\n",
        "lower_samples_df.R_calc.nunique()\n",
        "lower_samples_df.L_calc.nunique()\n",
        "both_samples_df.L_calc.nunique()\n",
        "both_samples_df.R_calc.nunique()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, I shall make a dataframes for calculated weights value to see whether I can achieve overfitting.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_values_df = df[(df.LD >= 4) & (df.LW >= 4) & (df.RD >= 4) & (df.RW >= 4)]\n",
        "lower_values_df = df[(df.LD <= 2) & (df.LW <= 2) & (df.RD <= 2) & (df.RW <= 2)]\n",
        "upper_values_df.groupby('C').count()\n",
        "lower_values_df.groupby('C').count()\n",
        "lower_values_df[lower_values_df.C == 'B'].describe()\n",
        "lower_values_df[lower_values_df.C == 'R'].describe()\n",
        "lower_values_df[lower_values_df.C == 'L'].describe()\n",
        "upper_values_df[upper_values_df.C == 'B'].describe()\n",
        "upper_values_df[upper_values_df.C == 'R'].describe()\n",
        "upper_values_df[upper_values_df.C == 'L'].describe()\n",
        "# Ok, it looks like there are very few samples for training purposes which is kinda ideal for overfitting.\n",
        "# But what's more ideal is the range of calculated weights that hopefully will introduce overfitting.\n",
        "# It looks like there are only maximum 6 samples, I shall pick just 4 for each class and value boundary.\n",
        "SEED = 1111\n",
        "\n",
        "# Making random samples for lower values by each class\n",
        "bal_df = lower_values_df[lower_values_df.C == 'B']\n",
        "left_df = lower_values_df[lower_values_df.C == 'L']\n",
        "right_df = lower_values_df[lower_values_df.C == 'R']\n",
        "\n",
        "bal_samples = bal_df.sample(n=4, random_state=SEED)\n",
        "left_samples = left_df.sample(n=4, random_state=SEED)\n",
        "right_samples = right_df.sample(n=4, random_state=SEED)\n",
        "\n",
        "lower_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
        "lower_samples_df.index\n",
        "\n",
        "# Making random samples for upper values by each class\n",
        "bal_df = upper_values_df[upper_values_df.C == 'B']\n",
        "left_df = upper_values_df[upper_values_df.C == 'L']\n",
        "right_df = upper_values_df[upper_values_df.C == 'R']\n",
        "bal_df.describe()\n",
        "left_df.describe()\n",
        "\n",
        "bal_samples = bal_df.sample(n=4, random_state=SEED)\n",
        "left_samples = left_df.sample(n=4, random_state=SEED)\n",
        "right_samples = right_df.sample(n=4, random_state=SEED)\n",
        "\n",
        "upper_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
        "upper_samples_df.index\n",
        "\n",
        "both_samples_df = pd.concat([lower_samples_df, upper_samples_df])\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For dataset description purpose\n",
        "lower_samples_df.describe()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upper_samples_df.describe()\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "separated_df = separate_dataframe_from_training_one(df, lower_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "X = lower_samples_df.loc[:, list_of_features]\n",
        "y = lower_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing tree into the dot format for observation\n",
        "# tree.export_graphviz(decision_tree_clf, out_file='lower_2_tree.dot')\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "separated_df = separate_dataframe_from_training_one(df, upper_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
        "X = upper_samples_df.loc[:, list_of_features]\n",
        "y = upper_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "separated_df = separate_dataframe_from_training_one(df, both_samples_df)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
        "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
        "X = both_samples_df.loc[:, list_of_features]\n",
        "y = both_samples_df.loc[:, ['C']]\n",
        "decision_tree_clf.fit(X, y)\n",
        "X = separated_df.loc[:, list_of_features]\n",
        "y = separated_df.loc[:, ['C']]\n",
        "accuracy_score(decision_tree_clf.predict(X), y)\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, I can see that the model is under performing for three categories of datasets,\n",
        "I will pick the lower tier for comparison since it looks like it\n",
        "\n",
        "Update: just did some look up at the tree algorithm structures in 'looking_at_decision_trees_structre.py' file and its generated pdf documents.\n",
        "\n",
        "At this point, I will have a look at SGDClassifier algorithm."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/home/pavel/.miniconda3/envs/scales/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}