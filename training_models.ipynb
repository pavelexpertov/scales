{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C  LW  LD  RW  RD\n",
       "0    B   1   1   1   1\n",
       "1    R   1   1   1   2\n",
       "2    R   1   1   1   3\n",
       "3    R   1   1   1   4\n",
       "4    R   1   1   1   5\n",
       "..  ..  ..  ..  ..  ..\n",
       "620  L   5   5   5   1\n",
       "621  L   5   5   5   2\n",
       "622  L   5   5   5   3\n",
       "623  L   5   5   5   4\n",
       "624  B   5   5   5   5\n",
       "\n",
       "[625 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('balance-scale.data', header=None, names=['C','LW','LD','RW','RD'])\n",
    "df\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "# Creating a list of records where the format is ['description', mean, std]\n",
    "recording_list = []\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 3 cross_validation Mean: 0.5633357870199975 0.1084098622894239\n",
      "With 5 cross_validation Mean: 0.5824 0.12189438051034183\n",
      "With 10 cross_validation Mean: 0.6721454173067076 0.1064649731893019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df.loc[:, ['LW','LD','RW','RD']]\n",
    "y = df.loc[:, ['C']]\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=3)\n",
    "print('With 3 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With 3 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print('With 5 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With 5 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print('With 10 cross_validation', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With 10 cross_validation DecisionTreeClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "It looks like that the mean of cross validation results is affected by the number of specified folds during cross validation. It means that the decision tree model gets more accurate as you feed it a lot more data.\n",
    "\n",
    "Let's look at the importance of the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24962917, 0.26291426, 0.22783845, 0.25961812])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.feature_importances_\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "It looks like that importances of the attributes are balanced out well with a difference between 1 to 3 percent. Thus it means that pretty much they are equal to each other.\n",
    "\n",
    "Even though the balanced class (i.e. 'B') is only 8% of the dataset, models still looks like to struggle to perform good on average even though the it would have trained on a large number of 'L' or 'R' classes.\n",
    "\n",
    "I need to look at other machine learning algorithms to see whether they perform better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With LogisticRegression Mean: 0.8512544802867383 0.05183392985486847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "enc_y = LabelEncoder()\n",
    "enc_y.fit(np.ravel(y.to_numpy()))\n",
    "encoded_y = enc_y.transform(np.ravel(y.to_numpy()))\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With LogisticRegression', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With LogisticRegression', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SGDClassifier Mean: 0.8574244751664107 0.09700179741186786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With SGDClassifier', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With SGDClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SVC Mean: 0.857731694828469 0.06931390559131817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With SVC', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With SVC', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With LinearSVC Mean: 0.8496671786994368 0.05562250420421758\n"
     ]
    }
   ],
   "source": [
    "scikit-learnfrom sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(max_iter=5000)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With LinearSVC', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With LinearSVC', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With RandomForestClassifier Mean: 0.6880184331797234 0.10553635102729655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With RandomForestClassifier', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With RandomForestClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With CategoricalNB Mean: 0.6940860215053762 0.10213202128757502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf = CategoricalNB()\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With CategoricalNB', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With CategoricalNB', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With NearestCentroid Mean: 0.7250640040962621 0.12521517465521045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "clf = NearestCentroid()\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With NearestCentroid', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With NearestCentroid', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNeighborsClassifier Mean: 0.7360727086533538 0.0644228441968043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With KNeighborsClassifier', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With KNeighborsClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With RadiusNeighborsClassifier Mean: 0.8672811059907835 0.04806896995866881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "clf = RadiusNeighborsClassifier(radius=2.0)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With RadiusNeighborsClassifier', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With RadiusNeighborsClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With MLPClassifier Mean: 0.9744495647721454 0.02860650605943155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(max_iter=1200)\n",
    "scores = cross_val_score(clf, X, encoded_y, cv=10)\n",
    "print('With MLPClassifier', 'Mean:', scores.mean(), scores.std())\n",
    "recording_list.append(['With MLPClassifier', scores.mean(), scores.std()])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With MLPClassifier Mean: 0.9744495647721454 std: 0.02860650605943155\n",
      "With RadiusNeighborsClassifier Mean: 0.8672811059907835 std: 0.04806896995866881\n",
      "With SVC Mean: 0.857731694828469 std: 0.06931390559131817\n",
      "With SGDClassifier Mean: 0.8574244751664107 std: 0.09700179741186786\n",
      "With LogisticRegression Mean: 0.8512544802867383 std: 0.05183392985486847\n",
      "With LinearSVC Mean: 0.8496671786994368 std: 0.05562250420421758\n",
      "With KNeighborsClassifier Mean: 0.7360727086533538 std: 0.0644228441968043\n",
      "With NearestCentroid Mean: 0.7250640040962621 std: 0.12521517465521045\n",
      "With CategoricalNB Mean: 0.6940860215053762 std: 0.10213202128757502\n",
      "With RandomForestClassifier Mean: 0.6880184331797234 std: 0.10553635102729655\n",
      "With 10 cross_validation DecisionTreeClassifier Mean: 0.6721454173067076 std: 0.1064649731893019\n",
      "With 5 cross_validation DecisionTreeClassifier Mean: 0.5824 std: 0.12189438051034183\n",
      "With 3 cross_validation DecisionTreeClassifier Mean: 0.5633357870199975 std: 0.1084098622894239\n"
     ]
    }
   ],
   "source": [
    "sorted_list = sorted(recording_list, key=lambda item: item[1], reverse=True)\n",
    "for classifier, mean, std in sorted_list:\n",
    "    print(classifier, 'Mean:', mean, 'std:', std)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "After experimenting with 11 algorithms, it looks like a neural network type classifier wins the testing round.\n",
    "\n",
    "Now I need to perform two things:\n",
    "    - I will need to delve further into algorithms to understand how they work as to have an idea why they perform either poorly or brilliantly. Algorithms I decided to learn about are:\n",
    "        1. MLPClassififer -- to understand neural networks in general\n",
    "        2. SGDClassifier -- to understand the stochastic classifier since it's second best\n",
    "        3. Decision Tree -- to understand decision trees since it's the worst model to train from the get go.\n",
    "    - During testing, I have been wondering about the current dataset and I think I have managed to notice few descrepencies I didn't see before. I will elaborate on this later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "```     ______                  __  _                ___\n",
    "    /  _/ /____  _________ _/ /_(_)___  ____     |__ \\\n",
    "    / // __/ _ \\/ ___/ __ `/ __/ / __ \\/ __ \\    __/ /\n",
    "  _/ // /_/  __/ /  / /_/ / /_/ / /_/ / / / /   / __/\n",
    " /___/\\__/\\___/_/   \\__,_/\\__/_/\\____/_/ /_/   /____/\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Purpose of this iteration is to see whether decision trees algorithms will be improved from its worse accuracy performance.\n",
    "\n",
    "The plan is to test different set of configurations and then do the same thing for feature engineered features.\n",
    "\n",
    "After reading about complex decisions trees that can fail to generalise a problem [Link](https://scikit-learn.org/stable/modules/tree.html#tree),\n",
    "the following has been advised to attempt to reduce the chances of such issue:\n",
    "- Set a required minimum samples at leaf nodes.\n",
    "- Set a depth level number to say how far the tree can go.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693190</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668894</td>\n",
       "      <td>0.098979</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668843</td>\n",
       "      <td>0.105015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667281</td>\n",
       "      <td>0.098959</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665719</td>\n",
       "      <td>0.099081</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
       "15               4                      1         0.693190        0.086092   \n",
       "43            None                      1         0.668894        0.098979   \n",
       "31               8                      1         0.668843        0.105015   \n",
       "39              10                      1         0.667281        0.098959   \n",
       "35               9                      1         0.665719        0.099081   \n",
       "\n",
       "    rank_test_score  \n",
       "15                1  \n",
       "43                2  \n",
       "31                3  \n",
       "39                4  \n",
       "35                5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing parameters with original dataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
    "}\n",
    "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
    "X = df.loc[:, ['LW','LD','RW','RD']]\n",
    "y = df.loc[:, ['C']]\n",
    "clf.fit(X, y)\n",
    "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  LW  LD  RW  RD  L_calc  R_calc\n",
       "0  B   1   1   1   1       1       1\n",
       "1  R   1   1   1   2       1       2\n",
       "2  R   1   1   1   3       1       3\n",
       "3  R   1   1   1   4       1       4\n",
       "4  R   1   1   1   5       1       5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating columns for the calculated weights.\n",
    "left_array = df.loc[:, ['LW', 'LD']].to_numpy()\n",
    "calculations = [item[0] * item[1] for item in left_array]\n",
    "df['L_calc'] = calculations\n",
    "right_array = df.loc[:, ['RW', 'RD']].to_numpy()\n",
    "calculations = [item[0] * item[1] for item in right_array]\n",
    "df['R_calc'] = calculations\n",
    "df.head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895571</td>\n",
       "      <td>0.089734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892396</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884460</td>\n",
       "      <td>0.098327</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881285</td>\n",
       "      <td>0.087815</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
       "31               8                      1         0.895571        0.089734   \n",
       "35               9                      1         0.892396        0.086711   \n",
       "39              10                      1         0.884511        0.090592   \n",
       "43            None                      1         0.884460        0.098327   \n",
       "27               7                      1         0.881285        0.087815   \n",
       "\n",
       "    rank_test_score  \n",
       "31                1  \n",
       "35                2  \n",
       "39                3  \n",
       "43                4  \n",
       "27                5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing parameters with a new feature of calculations of weight and height for each side.\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
    "}\n",
    "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
    "X = df.loc[:, ['LW','LD','RW','RD', 'L_calc', 'R_calc']]\n",
    "y = df.loc[:, ['C']]\n",
    "clf.fit(X, y)\n",
    "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974347</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
       "43            None                      1         0.977573        0.023943   \n",
       "39              10                      1         0.977573        0.023943   \n",
       "35               9                      1         0.977573        0.023943   \n",
       "31               8                      1         0.977573        0.023943   \n",
       "27               7                      1         0.974347        0.030634   \n",
       "\n",
       "    rank_test_score  \n",
       "43                1  \n",
       "39                1  \n",
       "35                1  \n",
       "31                1  \n",
       "27                5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the configurations by using just the calculations of the weights and distance.\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
    "}\n",
    "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
    "X = df.loc[:, [ 'L_calc', 'R_calc']]\n",
    "y = df.loc[:, ['C']]\n",
    "clf.fit(X, y)\n",
    "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "It looks like by introducing the calculations of weights and heights for each side helped the decision tree tremendously. Especially when only providing the calculatins on their own.\n",
    "\n",
    "I suppose that such calculations is kinda like a cheat, because I think it makes it easier for the model to 'sense' the algorithmic logic.\n",
    "\n",
    "I am very interested to see what will happen if I introduce boolean flag features (like making a hot-spot (I think) type features that are used for neural networks).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "      <th>left_flag</th>\n",
       "      <th>right_flag</th>\n",
       "      <th>balanced_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  LW  LD  RW  RD  L_calc  R_calc  left_flag  right_flag  balanced_flag\n",
       "0  B   1   1   1   1       1       1      False       False           True\n",
       "1  R   1   1   1   2       1       2      False        True          False\n",
       "2  R   1   1   1   3       1       3      False        True          False\n",
       "3  R   1   1   1   4       1       4      False        True          False\n",
       "4  R   1   1   1   5       1       5      False        True          False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating feature columns to represent hot-spotted boolean values for the classes.\n",
    "samples_array = df.loc[:, ['LW', 'LD', 'RW', 'RD']].to_numpy()\n",
    "df['left_flag'] = [(item[0] * item[1]) > (item[2] * item[3]) for item in samples_array]\n",
    "df['right_flag'] = [(item[0] * item[1]) < (item[2] * item[3]) for item in samples_array]\n",
    "df['balanced_flag'] = [(item[0] * item[1]) == (item[2] * item[3]) for item in samples_array]\n",
    "df.head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
       "43            None                      1              1.0             0.0   \n",
       "15               4                      1              1.0             0.0   \n",
       "27               7                      1              1.0             0.0   \n",
       "11               3                      1              1.0             0.0   \n",
       "31               8                      1              1.0             0.0   \n",
       "\n",
       "    rank_test_score  \n",
       "43                1  \n",
       "15                1  \n",
       "27                1  \n",
       "11                1  \n",
       "31                1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the configurations by using just the calculations of the weights and distance.\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
    "}\n",
    "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
    "X = df.loc[:, ['LW', 'LD', 'RW', 'RD', 'left_flag', 'balanced_flag', 'right_flag']]\n",
    "y = df.loc[:, ['C']]\n",
    "clf.fit(X, y)\n",
    "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
       "43            None                      1              1.0             0.0   \n",
       "15               4                      1              1.0             0.0   \n",
       "27               7                      1              1.0             0.0   \n",
       "11               3                      1              1.0             0.0   \n",
       "31               8                      1              1.0             0.0   \n",
       "\n",
       "    rank_test_score  \n",
       "43                1  \n",
       "15                1  \n",
       "27                1  \n",
       "11                1  \n",
       "31                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the configurations by using just the calculations of the weights and distance.\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'min_samples_leaf': [0.2, 0.4, 0.5, 1]\n",
    "}\n",
    "clf = GridSearchCV(decision_tree_clf, parameters, cv=10)\n",
    "X = df.loc[:, ['left_flag', 'balanced_flag', 'right_flag']]\n",
    "y = df.loc[:, ['C']]\n",
    "clf.fit(X, y)\n",
    "pd.DataFrame(clf.cv_results_).loc[:, ['param_max_depth', 'param_min_samples_leaf', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by=['rank_test_score']).head()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Conclusions after trying feature engineering:\n",
    "- Calculated weights on each side:\n",
    "  - with the rest of features, it's on average 90%\n",
    "  - on their own, it's staggering 97%\n",
    "- Boolean flags\n",
    "  - With or without the rest of the feautres, it's pretty much 100%.\n",
    "    - In other words, I have already done the job for the algorithm :smiley:.\n",
    "\n",
    "Thus, it seems that the calculated weights of the features helps to make better guesses about the incoming values whereas the boolean flags are cheats.\n",
    "\n",
    "The next experiment will see whether I can make a model from balanced dataset where there are equal number of samples for each class.\n",
    "\n",
    "Before I do that though, I need to look into overfitting problems of the algorithm. During experiments, I noticed that the decision tree's accuracy would decrease\n",
    "if I fed it less training data when I performed different cross-validations (i.e. k-folds).\n",
    "What I would like to see is whether samples that sit on each end of the range (e.g. on value 1 and 5 rather than inbetween them) that can affect the accuracy and only use original features and the calculated weights.\n",
    "I will make the rations of class samples balanced as to be consistent with the mentioned experiment.\n",
    "\n",
    "ToDo Overfitting Experiments:\n",
    "- [x] Only upper values of the range (i.e. 5 in weights and distance no matter what in other values as long as conditions are met)\n",
    "    - ~[ ] With original features~\n",
    "    - [x] With original features and the calculated weights\n",
    "- [x] Only lower values of the range (i.e. 1 in weights and distance no matter what in other values as long as conditions are met)\n",
    "    - ~[ ] With original features~\n",
    "    - [x] With original features and the calculated weights\n",
    "- [x] Upper and lower values of the range (i.e. both of the prior conditions)\n",
    "    - ~[ ] With original features~\n",
    "    - [x] With original features and the calculated weights\n",
    "\n",
    "Update: just did some look up at the tree algorithm structures in 'looking_at_decision_trees_structre.py' file and its generated pdf documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "upper_values_df = df[(df.LD == 5) | (df.LW == 5) | (df.RD == 5) | (df.RW == 5)]\n",
    "lower_values_df = df[(df.LD == 1) | (df.LW == 1) | (df.RD == 1) | (df.RW == 1)]\n",
    "upper_values_df.groupby('C').count()\n",
    "lower_values_df.groupby('C').count()\n",
    "\n",
    "# From the looks of it, I will choose 15 samples of each class for lower and upper values\n",
    "SEED = 1111\n",
    "\n",
    "# Making random samples for lower values by each class\n",
    "bal_df = lower_values_df[lower_values_df.C == 'B']\n",
    "left_df = lower_values_df[lower_values_df.C == 'L']\n",
    "right_df = lower_values_df[lower_values_df.C == 'R']\n",
    "\n",
    "bal_samples = bal_df.sample(n=15, random_state=SEED)\n",
    "left_samples = left_df.sample(n=15, random_state=SEED)\n",
    "right_samples = right_df.sample(n=15, random_state=SEED)\n",
    "\n",
    "lower_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
    "lower_samples_df.index\n",
    "\n",
    "# Making random samples for upper values by each class\n",
    "bal_df = upper_values_df[upper_values_df.C == 'B']\n",
    "left_df = upper_values_df[upper_values_df.C == 'L']\n",
    "right_df = upper_values_df[upper_values_df.C == 'R']\n",
    "bal_df.describe()\n",
    "left_df.describe()\n",
    "\n",
    "bal_samples = bal_df.sample(n=15, random_state=SEED)\n",
    "left_samples = left_df.sample(n=15, random_state=SEED)\n",
    "right_samples = right_df.sample(n=15, random_state=SEED)\n",
    "\n",
    "upper_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
    "upper_samples_df.index\n",
    "\n",
    "both_samples_df = pd.concat([lower_samples_df, upper_samples_df])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.533333</td>\n",
       "      <td>2.422222</td>\n",
       "      <td>2.488889</td>\n",
       "      <td>2.488889</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>5.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.501514</td>\n",
       "      <td>1.469213</td>\n",
       "      <td>1.546583</td>\n",
       "      <td>1.618392</td>\n",
       "      <td>4.957089</td>\n",
       "      <td>5.136717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LW         LD         RW         RD     L_calc     R_calc\n",
       "count  45.000000  45.000000  45.000000  45.000000  45.000000  45.000000\n",
       "mean    2.533333   2.422222   2.488889   2.488889   5.533333   5.577778\n",
       "std     1.501514   1.469213   1.546583   1.618392   4.957089   5.136717\n",
       "min     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000\n",
       "25%     1.000000   1.000000   1.000000   1.000000   3.000000   2.000000\n",
       "50%     2.000000   2.000000   2.000000   2.000000   4.000000   4.000000\n",
       "75%     4.000000   4.000000   4.000000   4.000000   5.000000   5.000000\n",
       "max     5.000000   5.000000   5.000000   5.000000  25.000000  25.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For dataset description purpose\n",
    "lower_samples_df.describe()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.466667</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.511111</td>\n",
       "      <td>3.511111</td>\n",
       "      <td>10.444444</td>\n",
       "      <td>11.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.470930</td>\n",
       "      <td>1.546256</td>\n",
       "      <td>1.440048</td>\n",
       "      <td>1.561209</td>\n",
       "      <td>6.276057</td>\n",
       "      <td>6.923244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LW         LD         RW         RD     L_calc     R_calc\n",
       "count  45.000000  45.000000  45.000000  45.000000  45.000000  45.000000\n",
       "mean    3.466667   3.200000   3.511111   3.511111  10.444444  11.977778\n",
       "std     1.470930   1.546256   1.440048   1.561209   6.276057   6.923244\n",
       "min     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000\n",
       "25%     2.000000   2.000000   2.000000   2.000000   5.000000   5.000000\n",
       "50%     4.000000   3.000000   4.000000   4.000000  10.000000  10.000000\n",
       "75%     5.000000   5.000000   5.000000   5.000000  15.000000  15.000000\n",
       "max     5.000000   5.000000   5.000000   5.000000  25.000000  25.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_samples_df.describe()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def separate_dataframe_from_training_one(original_df, training_df):\n",
    "    '''Return a newly-generated dataframe where one's rows don't exist in a training one'''\n",
    "    original_set = set(original_df.index)\n",
    "    training_set = set(training_df.index)\n",
    "    non_training_set = original_set - training_set\n",
    "    return original_df.iloc[list(non_training_set)]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051724137931035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "separated_df = separate_dataframe_from_training_one(df, lower_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "X = lower_samples_df.loc[:, list_of_features]\n",
    "y = lower_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "# Storing tree into the dot format for observation\n",
    "# tree.export_graphviz(decision_tree_clf, out_file='lower_1_tree.dot')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155172413793104"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated_df = separate_dataframe_from_training_one(df, upper_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
    "X = upper_samples_df.loc[:, list_of_features]\n",
    "y = upper_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521256931608133"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated_df = separate_dataframe_from_training_one(df, both_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
    "X = both_samples_df.loc[:, list_of_features]\n",
    "y = both_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "It looks like that the models still perform good even though I was expecting some overfitting problems. Even if there are only few samples to train from for particular boundaries\n",
    "(e.g. on average 70% accuracy for lower values and average 80)\n",
    "\n",
    "I believe it is because the samples have a wide range of values for weights and distances that still managed to make well-performed models\n",
    "(e.g. lower-values-only samples without the calculated weights would produce on average 59%).\n",
    "\n",
    "Thus, I shall make samples that only contain measurements that meet certain range criterial (i.e. maximum and minimum values)\n",
    "\n",
    "I believe this is because there's a wide range of the calculated weights for the classes and thus it helped the model\n",
    "to determine classes accurately. Like you can see below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the calculated weights\n",
    "upper_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
    "lower_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
    "both_samples_df.loc[:, ['L_calc', 'R_calc']].describe()\n",
    "\n",
    "lower_samples_df.R_calc.nunique()\n",
    "lower_samples_df.L_calc.nunique()\n",
    "both_samples_df.L_calc.nunique()\n",
    "both_samples_df.R_calc.nunique()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Thus, I shall make a dataframes for calculated weights value to see whether I can achieve overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "upper_values_df = df[(df.LD >= 4) & (df.LW >= 4) & (df.RD >= 4) & (df.RW >= 4)]\n",
    "lower_values_df = df[(df.LD <= 2) & (df.LW <= 2) & (df.RD <= 2) & (df.RW <= 2)]\n",
    "upper_values_df.groupby('C').count()\n",
    "lower_values_df.groupby('C').count()\n",
    "lower_values_df[lower_values_df.C == 'B'].describe()\n",
    "lower_values_df[lower_values_df.C == 'R'].describe()\n",
    "lower_values_df[lower_values_df.C == 'L'].describe()\n",
    "upper_values_df[upper_values_df.C == 'B'].describe()\n",
    "upper_values_df[upper_values_df.C == 'R'].describe()\n",
    "upper_values_df[upper_values_df.C == 'L'].describe()\n",
    "# Ok, it looks like there are very few samples for training purposes which is kinda ideal for overfitting.\n",
    "# But what's more ideal is the range of calculated weights that hopefully will introduce overfitting.\n",
    "# It looks like there are only maximum 6 samples, I shall pick just 4 for each class and value boundary.\n",
    "SEED = 1111\n",
    "\n",
    "# Making random samples for lower values by each class\n",
    "bal_df = lower_values_df[lower_values_df.C == 'B']\n",
    "left_df = lower_values_df[lower_values_df.C == 'L']\n",
    "right_df = lower_values_df[lower_values_df.C == 'R']\n",
    "\n",
    "bal_samples = bal_df.sample(n=4, random_state=SEED)\n",
    "left_samples = left_df.sample(n=4, random_state=SEED)\n",
    "right_samples = right_df.sample(n=4, random_state=SEED)\n",
    "\n",
    "lower_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
    "lower_samples_df.index\n",
    "\n",
    "# Making random samples for upper values by each class\n",
    "bal_df = upper_values_df[upper_values_df.C == 'B']\n",
    "left_df = upper_values_df[upper_values_df.C == 'L']\n",
    "right_df = upper_values_df[upper_values_df.C == 'R']\n",
    "bal_df.describe()\n",
    "left_df.describe()\n",
    "\n",
    "bal_samples = bal_df.sample(n=4, random_state=SEED)\n",
    "left_samples = left_df.sample(n=4, random_state=SEED)\n",
    "right_samples = right_df.sample(n=4, random_state=SEED)\n",
    "\n",
    "upper_samples_df = pd.concat([bal_samples, left_samples, right_samples])\n",
    "upper_samples_df.index\n",
    "\n",
    "both_samples_df = pd.concat([lower_samples_df, upper_samples_df])\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.193416</td>\n",
       "      <td>1.193416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LW         LD         RW         RD     L_calc     R_calc\n",
       "count  12.000000  12.000000  12.000000  12.000000  12.000000  12.000000\n",
       "mean    1.416667   1.500000   1.416667   1.500000   2.166667   2.166667\n",
       "std     0.514929   0.522233   0.514929   0.522233   1.193416   1.193416\n",
       "min     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000\n",
       "25%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000\n",
       "50%     1.000000   1.500000   1.000000   1.500000   2.000000   2.000000\n",
       "75%     2.000000   2.000000   2.000000   2.000000   2.500000   2.500000\n",
       "max     2.000000   2.000000   2.000000   2.000000   4.000000   4.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For dataset description purpose\n",
    "lower_samples_df.describe()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LW</th>\n",
       "      <th>LD</th>\n",
       "      <th>RW</th>\n",
       "      <th>RD</th>\n",
       "      <th>L_calc</th>\n",
       "      <th>R_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>19.916667</td>\n",
       "      <td>19.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>3.553701</td>\n",
       "      <td>3.553701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>21.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LW         LD         RW         RD     L_calc     R_calc\n",
       "count  12.000000  12.000000  12.000000  12.000000  12.000000  12.000000\n",
       "mean    4.416667   4.500000   4.416667   4.500000  19.916667  19.916667\n",
       "std     0.514929   0.522233   0.514929   0.522233   3.553701   3.553701\n",
       "min     4.000000   4.000000   4.000000   4.000000  16.000000  16.000000\n",
       "25%     4.000000   4.000000   4.000000   4.000000  16.000000  16.000000\n",
       "50%     4.000000   4.500000   4.000000   4.500000  20.000000  20.000000\n",
       "75%     5.000000   5.000000   5.000000   5.000000  21.250000  21.250000\n",
       "max     5.000000   5.000000   5.000000   5.000000  25.000000  25.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_samples_df.describe()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.399673735725938"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "separated_df = separate_dataframe_from_training_one(df, lower_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "X = lower_samples_df.loc[:, list_of_features]\n",
    "y = lower_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "# Storing tree into the dot format for observation\n",
    "# tree.export_graphviz(decision_tree_clf, out_file='lower_2_tree.dot')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27895595432300163"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated_df = separate_dataframe_from_training_one(df, upper_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
    "X = upper_samples_df.loc[:, list_of_features]\n",
    "y = upper_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339434276206323"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated_df = separate_dataframe_from_training_one(df, both_samples_df)\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "list_of_features = ['LW', 'LD', 'RW', 'RD', 'L_calc', 'R_calc']\n",
    "# list_of_features = ['LW', 'LD', 'RW', 'RD']\n",
    "X = both_samples_df.loc[:, list_of_features]\n",
    "y = both_samples_df.loc[:, ['C']]\n",
    "decision_tree_clf.fit(X, y)\n",
    "X = separated_df.loc[:, list_of_features]\n",
    "y = separated_df.loc[:, ['C']]\n",
    "accuracy_score(decision_tree_clf.predict(X), y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Ok, I can see that the model is under performing for three categories of datasets,\n",
    "I will pick the lower tier for comparison since it looks like it\n",
    "\n",
    "Update: just did some look up at the tree algorithm structures in 'looking_at_decision_trees_structre.py' file and its generated pdf documents.\n",
    "\n",
    "At this point, I will have a look at SGDClassifier algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
